{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from collections import defaultdict, Counter, OrderedDict\n",
    "import featureselection as fs\n",
    "import os.path\n",
    "import os\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "import datetime\n",
    "from operator import itemgetter\n",
    "import preprocessing as pp\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def softmax(x):\n",
    "    b = x.max()\n",
    "    y = np.exp(x - b)\n",
    "    return y / y.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(x):\n",
    "    return .5 * (1 + np.tanh(.5 * x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "def logistic_regression(weights, data, binary_label_vectors, threshold, learning_rate, word_indices_by_label):\n",
    "    '''\n",
    "    :param weights: a matrix of len(valid_words) rows and len(label_list)\n",
    "                    columns, where entry i,j is the weight for word i\n",
    "                    in documents with label j\n",
    "    :param data: a matrix of len(valid_words) rows and num_docs columns,\n",
    "                where entry i,j is the number of occurrences of word i\n",
    "                in document j\n",
    "    :param binary_label_vectors: a matrix of len(label_list) rows and\n",
    "                                num_docs cols, where each entry i,j is\n",
    "                                1 if document j has label i, and 0 otherwise\n",
    "    :param threshold: the value at which if all weights only change by less than\n",
    "                        this value, we claim the model has converged\n",
    "    :param learning rate: the scaling factor of the gradient to ensure we do not\n",
    "                            descend too quickly\n",
    "    :param word_indices: a dictionary where keys = indices and values = the index\n",
    "                        of that word that the number corresponds to\n",
    "    :return: the weights matrix, updated after running gradient descent on it \n",
    "    '''\n",
    "    for label in binary_label_vectors.keys():\n",
    "        print(\"Training label\", label)\n",
    "        labels = np.asarray(binary_label_vectors[label]).reshape(1, data.shape[1])\n",
    "        # Labels.shape = 1x5\n",
    "        num_docs = labels.shape[0]\n",
    "        weight_vector = np.transpose(weights[label]).reshape(1, weights[label].shape[0])\n",
    "        converged = False\n",
    "        k = 1\n",
    "        num_docs = labels.shape[0]\n",
    "        start = time.time()\n",
    "        data_1 = np.asarray([[0 for i in range(data.shape[1])] for j in range(weight_vector.shape[1])])\n",
    "        print(data_1.shape)\n",
    "        for i in range(data.shape[1]):\n",
    "            data_1[:, i] = [data[j][i] for j in range(data.shape[0]) if j in word_indices_by_label[label]]\n",
    "        print(label, data_1.shape)\n",
    "        print(time.time() - start)\n",
    "        while not converged and k < 50:\n",
    "            converged = True\n",
    "            print(label, \"Iteration:\", k)\n",
    "            # start = time.time()\n",
    "            weight_eval = sigmoid(np.dot(weight_vector, data_1))\n",
    "            # weight_eval.shape = 1x5\n",
    "            # print(\"W^T * x\", time.time() - start)\n",
    "            # start = time.time()\n",
    "            loss = np.subtract(labels, weight_eval)\n",
    "            # loss.shape = 1x5\n",
    "            gradient = np.dot(loss, np.transpose(data_1))\n",
    "            gradient *= learning_rate\n",
    "            # print(\"Gradient: \", time.time()-start)\n",
    "            # start = time.time()\n",
    "            updated_weights = weight_vector + gradient\n",
    "            delta = weight_vector - updated_weights\n",
    "            weight_vector = updated_weights\n",
    "            for i in range(len(delta)):\n",
    "                for j in range(len(delta[0])):\n",
    "                    if np.absolute(delta[i][j]) >= threshold:\n",
    "                        converged = False\n",
    "            k += 1\n",
    "            # print(\"Check convergence: \", time.time()-start)\n",
    "            # gradient.shape = 1x308\n",
    "        weights[label] = weight_vector\n",
    "    return weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_new_cats_file(filename):\n",
    "    '''\n",
    "    This is a utility function that will rearrange the elements\n",
    "    in the cats.txt file so that they are sorted by numbers instead\n",
    "    '''\n",
    "    with open(filename, \"r\") as f:\n",
    "        training_lines = []\n",
    "        test_lines = []\n",
    "        for line in f:\n",
    "            elems = line.split()\n",
    "            if line[0:8] == \"training\":\n",
    "                num = int(elems[0][9:len(elems[0])])\n",
    "                training_lines.append((num, elems[1:]))\n",
    "            else:\n",
    "                num = int(elems[0][5:len(elems[0])])\n",
    "                test_lines.append((num, elems[1:]))\n",
    "    training_lines = sorted(training_lines, key=lambda x: x[0])\n",
    "    test_lines = sorted(test_lines, key=lambda x: x[0])\n",
    "    with open(\"cats2.txt\", \"w\") as f:\n",
    "        for num, labels in training_lines:\n",
    "            f.write(\"training/\" + str(num) + \" \" + \" \".join(labels) + \"\\n\")\n",
    "        for num, labels in test_lines:\n",
    "            f.write(\"test/\" + str(num) + \" \" + \" \".join(labels) + \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def construct_feature_matrix(dir_path, valid_words):\n",
    "    '''\n",
    "    This function will take text vectors of each document\n",
    "    and put them into a matrix.\n",
    "    :param dir_path: path to the directory containing all the\n",
    "                    training files\n",
    "    :param valid_words: a dictionary where keys are all the \n",
    "                        valid words in the corpus\n",
    "    '''\n",
    "    feature_matrix = []\n",
    "    sorted_files = sorted([int(file[0:len(file) - 4])  for file in os.listdir(dir_path)])\n",
    "    for num in sorted_files:\n",
    "        filepath = dir_path + \"\\\\\" + str(num) + \".txt\"\n",
    "        text_vector = pp.vectorize_text(valid_words, filepath)\n",
    "        word_freq = {word: 0 for word in valid_words}\n",
    "        freq = Counter(text_vector)\n",
    "        for word in freq.keys():\n",
    "            word_freq[word] = freq[word]\n",
    "        frequencies = [y for x,y in word_freq.items()]\n",
    "        feature_matrix.append(frequencies)\n",
    "    return np.transpose(np.asarray(feature_matrix))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_text_vectors(dir_path, valid_words):\n",
    "    text_vectors = defaultdict()\n",
    "    sorted_files = sorted([int(file[0:len(file) - 4])  for file in os.listdir(dir_path)])\n",
    "    for num in sorted_files:\n",
    "        frequencies = {word: 0 for word in valid_words}\n",
    "        filepath = dir_path + \"\\\\\" + str(num) + \".txt\"\n",
    "        text_vector = pp.vectorize_text(valid_words, filepath)\n",
    "        freq = Counter(text_vector)\n",
    "        for word in freq.keys():\n",
    "            frequencies[word] = freq[word]\n",
    "        text_vectors[num] = np.asarray([y for x,y in frequencies.items()])\n",
    "    return text_vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def construct_binary_label_vectors(indexed_labels, filename, num_docs):\n",
    "    '''\n",
    "    This function will return a dictionary where keys = labels \n",
    "    and values = a 2D vector of len(label_list) rows and len(num_docs)\n",
    "    cols where each entry i,j is 1 if word i has label j and 0 otherwise\n",
    "    :param label_list: dict where keys = labels and values = index\n",
    "                        that maps to that label\n",
    "    :param filename: name of the file that maps doc numbers to \n",
    "                    labels\n",
    "    '''\n",
    "    binary_label_vectors = {label: [0.0 for i in range(num_docs)] for label in indexed_labels.keys()}\n",
    "    j = 0\n",
    "    with open(filename, \"r\") as f:\n",
    "        for line in f:\n",
    "            terms = line.split()\n",
    "            if terms[0][0:4] == \"test\":\n",
    "                continue\n",
    "            for elem in terms[1:]:\n",
    "                binary_label_vectors[elem][j] = 1.0\n",
    "            j += 1\n",
    "    return binary_label_vectors                              "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cocoa 147\n",
      "sorghum 83\n",
      "oat 42\n",
      "barley 42\n",
      "corn 83\n",
      "wheat 83\n",
      "grain 83\n",
      "sunseed 46\n",
      "oilseed 46\n",
      "soybean 46\n",
      "sun-oil 46\n",
      "soy-oil 46\n",
      "lin-oil 46\n",
      "veg-oil 46\n",
      "earn 28\n",
      "acq 87\n"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    dir_path = \"C:\\\\Users\\\\ksing\\\\OneDrive\\\\Documents\\\\TextClassifiers\\\\MiniTrainingSet\"\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    # valid_words = fs.most_useful_features(\"cdmscores.txt\")\n",
    "    number_labels_training, number_labels_test = pp.add_labels_to_samples(\"cats1.txt\")\n",
    "    prior_probs = pp.compute_prior_probabilities(number_labels_training)\n",
    "    valid_words_label, valid_words = pp.get_valid_words(dir_path, stop_words, prior_probs.keys(), number_labels_training)\n",
    "    for label, vector in valid_words_label.items():\n",
    "        print(label,len(vector))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "    word_indices = {i: word for i, word in enumerate(valid_words.keys())}\n",
    "    word_indices_by_label = {label: {} for label in prior_probs.keys()}\n",
    "    for label in prior_probs.keys():\n",
    "        word_indices_by_label[label] = {i: word for i, word in enumerate(valid_words.keys()) \n",
    "                                        if word in valid_words_label[label]}\n",
    "    indexed_labels = {label: i for i, label in enumerate(prior_probs.keys())}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(308, 5)\n"
     ]
    }
   ],
   "source": [
    "    for label, vector in valid_words_label.items():\n",
    "        valid_words_label[label] = OrderedDict(sorted(vector.items(), key=lambda t: t[0]))\n",
    "    feature_matrix = construct_feature_matrix(dir_path, valid_words)\n",
    "    print(feature_matrix.shape)\n",
    "    # Each column in the feature matrix corresponds to an individual document"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "    weights = {label: np.array([]) for label in prior_probs.keys()}\n",
    "    for label in prior_probs.keys():\n",
    "        weights[label] = np.asarray([np.random.uniform(0,0.005) for i in range(len(valid_words_label[label].keys()))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "    num_docs = len([name for name in os.listdir(dir_path) if os.path.isfile(os.path.join(dir_path, name))])\n",
    "    binary_label_vectors = construct_binary_label_vectors(indexed_labels, \"cats1.txt\", num_docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training label cocoa\n",
      "(147, 5)\n",
      "cocoa (147, 5)\n",
      "0.0\n",
      "cocoa Iteration: 1\n",
      "cocoa Iteration: 2\n",
      "cocoa Iteration: 3\n",
      "cocoa Iteration: 4\n",
      "cocoa Iteration: 5\n",
      "cocoa Iteration: 6\n",
      "cocoa Iteration: 7\n",
      "cocoa Iteration: 8\n",
      "cocoa Iteration: 9\n",
      "cocoa Iteration: 10\n",
      "cocoa Iteration: 11\n",
      "cocoa Iteration: 12\n",
      "cocoa Iteration: 13\n",
      "cocoa Iteration: 14\n",
      "Training label sorghum\n",
      "(83, 5)\n",
      "sorghum (83, 5)\n",
      "0.0\n",
      "sorghum Iteration: 1\n",
      "sorghum Iteration: 2\n",
      "sorghum Iteration: 3\n",
      "sorghum Iteration: 4\n",
      "sorghum Iteration: 5\n",
      "sorghum Iteration: 6\n",
      "sorghum Iteration: 7\n",
      "sorghum Iteration: 8\n",
      "sorghum Iteration: 9\n",
      "sorghum Iteration: 10\n",
      "sorghum Iteration: 11\n",
      "sorghum Iteration: 12\n",
      "sorghum Iteration: 13\n",
      "sorghum Iteration: 14\n",
      "sorghum Iteration: 15\n",
      "Training label oat\n",
      "(42, 5)\n",
      "oat (42, 5)\n",
      "0.0\n",
      "oat Iteration: 1\n",
      "oat Iteration: 2\n",
      "oat Iteration: 3\n",
      "oat Iteration: 4\n",
      "oat Iteration: 5\n",
      "oat Iteration: 6\n",
      "oat Iteration: 7\n",
      "oat Iteration: 8\n",
      "oat Iteration: 9\n",
      "oat Iteration: 10\n",
      "oat Iteration: 11\n",
      "oat Iteration: 12\n",
      "oat Iteration: 13\n",
      "oat Iteration: 14\n",
      "oat Iteration: 15\n",
      "oat Iteration: 16\n",
      "oat Iteration: 17\n",
      "oat Iteration: 18\n",
      "Training label barley\n",
      "(42, 5)\n",
      "barley (42, 5)\n",
      "0.0\n",
      "barley Iteration: 1\n",
      "barley Iteration: 2\n",
      "barley Iteration: 3\n",
      "barley Iteration: 4\n",
      "barley Iteration: 5\n",
      "barley Iteration: 6\n",
      "barley Iteration: 7\n",
      "barley Iteration: 8\n",
      "barley Iteration: 9\n",
      "barley Iteration: 10\n",
      "barley Iteration: 11\n",
      "barley Iteration: 12\n",
      "barley Iteration: 13\n",
      "barley Iteration: 14\n",
      "barley Iteration: 15\n",
      "barley Iteration: 16\n",
      "barley Iteration: 17\n",
      "barley Iteration: 18\n",
      "Training label corn\n",
      "(83, 5)\n",
      "corn (83, 5)\n",
      "0.0\n",
      "corn Iteration: 1\n",
      "corn Iteration: 2\n",
      "corn Iteration: 3\n",
      "corn Iteration: 4\n",
      "corn Iteration: 5\n",
      "corn Iteration: 6\n",
      "corn Iteration: 7\n",
      "corn Iteration: 8\n",
      "corn Iteration: 9\n",
      "corn Iteration: 10\n",
      "corn Iteration: 11\n",
      "corn Iteration: 12\n",
      "corn Iteration: 13\n",
      "corn Iteration: 14\n",
      "corn Iteration: 15\n",
      "Training label wheat\n",
      "(83, 5)\n",
      "wheat (83, 5)\n",
      "0.0\n",
      "wheat Iteration: 1\n",
      "wheat Iteration: 2\n",
      "wheat Iteration: 3\n",
      "wheat Iteration: 4\n",
      "wheat Iteration: 5\n",
      "wheat Iteration: 6\n",
      "wheat Iteration: 7\n",
      "wheat Iteration: 8\n",
      "wheat Iteration: 9\n",
      "wheat Iteration: 10\n",
      "wheat Iteration: 11\n",
      "wheat Iteration: 12\n",
      "wheat Iteration: 13\n",
      "wheat Iteration: 14\n",
      "wheat Iteration: 15\n",
      "Training label grain\n",
      "(83, 5)\n",
      "grain (83, 5)\n",
      "0.0009899139404296875\n",
      "grain Iteration: 1\n",
      "grain Iteration: 2\n",
      "grain Iteration: 3\n",
      "grain Iteration: 4\n",
      "grain Iteration: 5\n",
      "grain Iteration: 6\n",
      "grain Iteration: 7\n",
      "grain Iteration: 8\n",
      "grain Iteration: 9\n",
      "grain Iteration: 10\n",
      "grain Iteration: 11\n",
      "grain Iteration: 12\n",
      "grain Iteration: 13\n",
      "grain Iteration: 14\n",
      "grain Iteration: 15\n",
      "Training label sunseed\n",
      "(46, 5)\n",
      "sunseed (46, 5)\n",
      "0.0009963512420654297\n",
      "sunseed Iteration: 1\n",
      "sunseed Iteration: 2\n",
      "sunseed Iteration: 3\n",
      "sunseed Iteration: 4\n",
      "sunseed Iteration: 5\n",
      "sunseed Iteration: 6\n",
      "sunseed Iteration: 7\n",
      "sunseed Iteration: 8\n",
      "sunseed Iteration: 9\n",
      "sunseed Iteration: 10\n",
      "sunseed Iteration: 11\n",
      "sunseed Iteration: 12\n",
      "sunseed Iteration: 13\n",
      "sunseed Iteration: 14\n",
      "sunseed Iteration: 15\n",
      "sunseed Iteration: 16\n",
      "sunseed Iteration: 17\n",
      "sunseed Iteration: 18\n",
      "sunseed Iteration: 19\n",
      "sunseed Iteration: 20\n",
      "sunseed Iteration: 21\n",
      "sunseed Iteration: 22\n",
      "sunseed Iteration: 23\n",
      "sunseed Iteration: 24\n",
      "Training label oilseed\n",
      "(46, 5)\n",
      "oilseed (46, 5)\n",
      "0.0\n",
      "oilseed Iteration: 1\n",
      "oilseed Iteration: 2\n",
      "oilseed Iteration: 3\n",
      "oilseed Iteration: 4\n",
      "oilseed Iteration: 5\n",
      "oilseed Iteration: 6\n",
      "oilseed Iteration: 7\n",
      "oilseed Iteration: 8\n",
      "oilseed Iteration: 9\n",
      "oilseed Iteration: 10\n",
      "oilseed Iteration: 11\n",
      "oilseed Iteration: 12\n",
      "oilseed Iteration: 13\n",
      "oilseed Iteration: 14\n",
      "oilseed Iteration: 15\n",
      "oilseed Iteration: 16\n",
      "oilseed Iteration: 17\n",
      "oilseed Iteration: 18\n",
      "oilseed Iteration: 19\n",
      "oilseed Iteration: 20\n",
      "oilseed Iteration: 21\n",
      "oilseed Iteration: 22\n",
      "oilseed Iteration: 23\n",
      "oilseed Iteration: 24\n",
      "Training label soybean\n",
      "(46, 5)\n",
      "soybean (46, 5)\n",
      "0.0\n",
      "soybean Iteration: 1\n",
      "soybean Iteration: 2\n",
      "soybean Iteration: 3\n",
      "soybean Iteration: 4\n",
      "soybean Iteration: 5\n",
      "soybean Iteration: 6\n",
      "soybean Iteration: 7\n",
      "soybean Iteration: 8\n",
      "soybean Iteration: 9\n",
      "soybean Iteration: 10\n",
      "soybean Iteration: 11\n",
      "soybean Iteration: 12\n",
      "soybean Iteration: 13\n",
      "soybean Iteration: 14\n",
      "soybean Iteration: 15\n",
      "soybean Iteration: 16\n",
      "soybean Iteration: 17\n",
      "soybean Iteration: 18\n",
      "soybean Iteration: 19\n",
      "soybean Iteration: 20\n",
      "soybean Iteration: 21\n",
      "soybean Iteration: 22\n",
      "soybean Iteration: 23\n",
      "soybean Iteration: 24\n",
      "Training label sun-oil\n",
      "(46, 5)\n",
      "sun-oil (46, 5)\n",
      "0.0\n",
      "sun-oil Iteration: 1\n",
      "sun-oil Iteration: 2\n",
      "sun-oil Iteration: 3\n",
      "sun-oil Iteration: 4\n",
      "sun-oil Iteration: 5\n",
      "sun-oil Iteration: 6\n",
      "sun-oil Iteration: 7\n",
      "sun-oil Iteration: 8\n",
      "sun-oil Iteration: 9\n",
      "sun-oil Iteration: 10\n",
      "sun-oil Iteration: 11\n",
      "sun-oil Iteration: 12\n",
      "sun-oil Iteration: 13\n",
      "sun-oil Iteration: 14\n",
      "sun-oil Iteration: 15\n",
      "sun-oil Iteration: 16\n",
      "sun-oil Iteration: 17\n",
      "sun-oil Iteration: 18\n",
      "sun-oil Iteration: 19\n",
      "sun-oil Iteration: 20\n",
      "sun-oil Iteration: 21\n",
      "sun-oil Iteration: 22\n",
      "sun-oil Iteration: 23\n",
      "sun-oil Iteration: 24\n",
      "Training label soy-oil\n",
      "(46, 5)\n",
      "soy-oil (46, 5)\n",
      "0.0009992122650146484\n",
      "soy-oil Iteration: 1\n",
      "soy-oil Iteration: 2\n",
      "soy-oil Iteration: 3\n",
      "soy-oil Iteration: 4\n",
      "soy-oil Iteration: 5\n",
      "soy-oil Iteration: 6\n",
      "soy-oil Iteration: 7\n",
      "soy-oil Iteration: 8\n",
      "soy-oil Iteration: 9\n",
      "soy-oil Iteration: 10\n",
      "soy-oil Iteration: 11\n",
      "soy-oil Iteration: 12\n",
      "soy-oil Iteration: 13\n",
      "soy-oil Iteration: 14\n",
      "soy-oil Iteration: 15\n",
      "soy-oil Iteration: 16\n",
      "soy-oil Iteration: 17\n",
      "soy-oil Iteration: 18\n",
      "soy-oil Iteration: 19\n",
      "soy-oil Iteration: 20\n",
      "soy-oil Iteration: 21\n",
      "soy-oil Iteration: 22\n",
      "soy-oil Iteration: 23\n",
      "soy-oil Iteration: 24\n",
      "Training label lin-oil\n",
      "(46, 5)\n",
      "lin-oil (46, 5)\n",
      "0.0\n",
      "lin-oil Iteration: 1\n",
      "lin-oil Iteration: 2\n",
      "lin-oil Iteration: 3\n",
      "lin-oil Iteration: 4\n",
      "lin-oil Iteration: 5\n",
      "lin-oil Iteration: 6\n",
      "lin-oil Iteration: 7\n",
      "lin-oil Iteration: 8\n",
      "lin-oil Iteration: 9\n",
      "lin-oil Iteration: 10\n",
      "lin-oil Iteration: 11\n",
      "lin-oil Iteration: 12\n",
      "lin-oil Iteration: 13\n",
      "lin-oil Iteration: 14\n",
      "lin-oil Iteration: 15\n",
      "lin-oil Iteration: 16\n",
      "lin-oil Iteration: 17\n",
      "lin-oil Iteration: 18\n",
      "lin-oil Iteration: 19\n",
      "lin-oil Iteration: 20\n",
      "lin-oil Iteration: 21\n",
      "lin-oil Iteration: 22\n",
      "lin-oil Iteration: 23\n",
      "lin-oil Iteration: 24\n",
      "Training label veg-oil\n",
      "(46, 5)\n",
      "veg-oil (46, 5)\n",
      "0.0009968280792236328\n",
      "veg-oil Iteration: 1\n",
      "veg-oil Iteration: 2\n",
      "veg-oil Iteration: 3\n",
      "veg-oil Iteration: 4\n",
      "veg-oil Iteration: 5\n",
      "veg-oil Iteration: 6\n",
      "veg-oil Iteration: 7\n",
      "veg-oil Iteration: 8\n",
      "veg-oil Iteration: 9\n",
      "veg-oil Iteration: 10\n",
      "veg-oil Iteration: 11\n",
      "veg-oil Iteration: 12\n",
      "veg-oil Iteration: 13\n",
      "veg-oil Iteration: 14\n",
      "veg-oil Iteration: 15\n",
      "veg-oil Iteration: 16\n",
      "veg-oil Iteration: 17\n",
      "veg-oil Iteration: 18\n",
      "veg-oil Iteration: 19\n",
      "veg-oil Iteration: 20\n",
      "veg-oil Iteration: 21\n",
      "veg-oil Iteration: 22\n",
      "veg-oil Iteration: 23\n",
      "veg-oil Iteration: 24\n",
      "Training label earn\n",
      "(28, 5)\n",
      "earn (28, 5)\n",
      "0.000997304916381836\n",
      "earn Iteration: 1\n",
      "earn Iteration: 2\n",
      "earn Iteration: 3\n",
      "earn Iteration: 4\n",
      "earn Iteration: 5\n",
      "earn Iteration: 6\n",
      "earn Iteration: 7\n",
      "earn Iteration: 8\n",
      "earn Iteration: 9\n",
      "earn Iteration: 10\n",
      "earn Iteration: 11\n",
      "earn Iteration: 12\n",
      "Training label acq\n",
      "(87, 5)\n",
      "acq (87, 5)\n",
      "0.0\n",
      "acq Iteration: 1\n",
      "acq Iteration: 2\n",
      "acq Iteration: 3\n",
      "acq Iteration: 4\n",
      "acq Iteration: 5\n",
      "acq Iteration: 6\n",
      "acq Iteration: 7\n",
      "acq Iteration: 8\n",
      "acq Iteration: 9\n",
      "acq Iteration: 10\n",
      "acq Iteration: 11\n",
      "acq Iteration: 12\n",
      "acq Iteration: 13\n",
      "acq Iteration: 14\n",
      "acq Iteration: 15\n",
      "acq Iteration: 16\n",
      "acq Iteration: 17\n",
      "acq Iteration: 18\n"
     ]
    }
   ],
   "source": [
    "    trained_weights = logistic_regression(weights, feature_matrix, binary_label_vectors, 0.01, 0.01, word_indices_by_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5 5\n"
     ]
    }
   ],
   "source": [
    "    successes = 0\n",
    "    earns = 0\n",
    "    j = 0\n",
    "    dir_path = \"C:\\\\Users\\\\ksing\\\\OneDrive\\\\Documents\\\\TextClassifiers\\\\MiniTrainingSet\"\n",
    "    for file in os.listdir(dir_path):\n",
    "        num = int(file[0:len(file) - 4])\n",
    "        filepath = dir_path + \"\\\\\" + file\n",
    "        vector = pp.vectorize_text(valid_words, filepath)\n",
    "        probs = []\n",
    "        for label, w in trained_weights.items():\n",
    "            frequencies = {word: 0 for word in valid_words_label[label]}\n",
    "            freq = Counter(vector)\n",
    "            for word in freq.keys():\n",
    "                if word in frequencies:\n",
    "                    frequencies[word] = freq[word]\n",
    "            counts = np.asarray([v for v in frequencies.values()])\n",
    "            prob = np.dot(w, counts)\n",
    "            probs.append([label, prob[0]])\n",
    "        probs = sorted(probs, key=lambda t: t[1], reverse=True)\n",
    "        just_scores = np.array([y for x,y in probs])\n",
    "        just_scores = softmax(just_scores)\n",
    "        for i in range(len(just_scores)):\n",
    "            probs[i][1] = just_scores[i]\n",
    "        s,e,b = pp.accuracy_model(num, number_labels_test, probs)\n",
    "        earns += e\n",
    "        successes += s\n",
    "        j += 1\n",
    "        # First run, 86.07% accuracy\n",
    "        # Cutting feature set to around 6700 increased accuracy up to 86.20%\n",
    "        # Cutting to 5000 increases accuracy to 86.22%, with 1944 \"Earn\" labels\n",
    "            # Perhaps applying tf_idf transformations to these frequencies\n",
    "            # should reduce this number\n",
    "        # With new feature sets, accuracy drops to 83.99%, but it runs much faster, although not fast enough\n",
    "        # The main overhead comes from trimming the data vectors\n",
    "        \n",
    "    print(successes, j)\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
